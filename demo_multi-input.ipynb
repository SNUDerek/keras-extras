{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-validation script for keras models\n",
    "\n",
    "this model demonstrates a multi-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/envs/oldkeras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/derek/miniconda3/envs/oldkeras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict GPU usage here - just for testing\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data construction\n",
    "\n",
    "we will compare texts in the Brown corpus from different genres provided by NLTK.\n",
    "\n",
    "the model will accept two lines of text, and try to classify as `same-source==1` or `different-source==0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "government = [s for s in brown.sents(categories=['government']) if len(s) > 30]\n",
    "religion = [s for s in brown.sents(categories=['religion']) if len(s) > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some samples\n",
    "def generateData(a, b, samples=1000):\n",
    "    x1, x2, y = [], [], []\n",
    "    for i in range(samples):\n",
    "        # decide whether to use same of different\n",
    "        g = np.random.randint(2)\n",
    "        h = np.random.randint(2)\n",
    "        if g > 0:\n",
    "            a_s = a[:]\n",
    "        else:\n",
    "            a_s = b[:]\n",
    "        if h > 0:\n",
    "            b_s = a[:]\n",
    "        else:\n",
    "            b_s = b[:]\n",
    "        x1.append(a_s[np.random.randint(len(a_s))])\n",
    "        x2.append(b_s[np.random.randint(len(b_s))])\n",
    "        if g == h:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    return x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, y = generateData(government, religion, samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# character-tokenize\n",
    "import re\n",
    "def charTokenize(txt):\n",
    "    seqs = []\n",
    "    for l in txt:\n",
    "        ll = ' '.join(l).lower()\n",
    "        ll = re.sub(r'[^0-9a-z\\s]', '', ll)\n",
    "        seqs.append(list(ll))\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = charTokenize(x1)\n",
    "x2 = charTokenize(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index and pad the data\n",
    "class CharIndexer:\n",
    "    def __init__(self, max_len=64, chars='abcdefghijklmnopqrstuvwxyz0123456789 '):\n",
    "        self.char2idx=dict([(c, i+1) for i, c in enumerate(list(chars))]+[('O', 0)])\n",
    "        self.idx2char=dict([(i+1, c) for i, c in enumerate(list(chars))]+[(0, 'O')])\n",
    "        self.max_len=max_len\n",
    "    \n",
    "    def transform(self, lol):\n",
    "        seqs = []\n",
    "        for l in lol:\n",
    "            s = [self.char2idx[c] for c in l]\n",
    "            s = s + [0 for _ in range(self.max_len)]\n",
    "            s = s[:self.max_len]\n",
    "            seqs.append(s)\n",
    "        return np.array(seqs)\n",
    "    \n",
    "    def inverse_transform(self, lol, no_pad=True):\n",
    "        txt = []\n",
    "        for l in lol:\n",
    "            l = [self.idx2char[i] for i in l]\n",
    "            if no_pad:\n",
    "                l = [c for c in l if c != 'O']\n",
    "            txt.append(l)\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxr = CharIndexer()\n",
    "x1 = idxr.transform(x1)\n",
    "x2 = idxr.transform(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : throughout these exciting years i have been fortunate for  altho \t it would seem  then  that movable property and equipment is not \n",
      "0 : the startling statement in a respectable periodical that  cathol \t petitioner was not entitled  either in the administrative hearin\n",
      "1 : to ask me to believe that so inexpressibly marvelous a book was  \t ironically  these are the groups which have doubled or tripled t\n",
      "1 :  about 30 of the expenditures for the department of defense in 1 \t this system is divided into a forest highway system  administere\n",
      "1 :  wherefore also he  god  drove him  man  out of paradise  and re \t racial discrimination is wrong  then  not because it goes agains\n",
      "0 : the startling statement in a respectable periodical that  cathol \t if launched in a careful but determined way within the next few \n",
      "0 : mr philip toynbee affirms at one point that if he shared the ant \t it is vitally important that the new us aid program should encou\n",
      "1 : again  as faith reveals god my father and christ my saviour  i f \t africans and asians tend to consider not only missions but the l\n",
      "1 : on those rare occasions when a faculty member on tenure is not m \t accordingly  if it is not repealed by the congress at its presen\n",
      "1 : this condition will undoubtedly continue until such time as a st \t in that ownership of all vehicles rests with the state motor poo\n"
     ]
    }
   ],
   "source": [
    "# check data and transformers\n",
    "for i in range(10):\n",
    "    print(y[i], \":\", ''.join(idxr.inverse_transform([x1[i]])[0]), '\\t', ''.join(idxr.inverse_transform([x2[i]])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of y's and reshape\n",
    "print(len([x for x in y if x==0]), len([x for x in y if x==1]))\n",
    "y = np.array(y)[:, np.newaxis]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define hyperparameters to search over\n",
    "\n",
    "if we define constants with UPPERCASE, they won't be shown in the `verbose` printout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'embed_size' : [100, 200],\n",
    "    'cell_size': [100, 200],\n",
    "    'drop_rate': [0.25, 0.5],\n",
    "    'OPTIMIZER' : ['adam'],\n",
    "    'MAXLEN': [64],\n",
    "    'VOCAB' : [len(idxr.char2idx)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model testing\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Bidirectional, Embedding, Dropout, LSTM, Concatenate, Dense, Activation\n",
    "\n",
    "def getModel(config):\n",
    "\n",
    "    input1 = Input((config['MAXLEN'],))\n",
    "    input2 = Input((config['MAXLEN'],))\n",
    "\n",
    "    embedd = Embedding(config['VOCAB'], config['embed_size'], input_length=config['MAXLEN'])\n",
    "\n",
    "    ## RNN\n",
    "    lstm1 = Bidirectional(LSTM(config['cell_size'], return_sequences=True))\n",
    "    lstm2 = Bidirectional(LSTM(config['cell_size']))\n",
    "\n",
    "    x1r = embedd(input1)\n",
    "    x1r = Dropout(config['drop_rate'])(x1r)\n",
    "    x1r = lstm1(x1r)\n",
    "    x1r = Dropout(config['drop_rate'])(x1r)\n",
    "    x1r = lstm2(x1r)\n",
    "\n",
    "    x2r = embedd(input2)\n",
    "    x2r = Dropout(config['drop_rate'])(x2r)\n",
    "    x2r = lstm1(x2r)\n",
    "    x2r = Dropout(config['drop_rate'])(x2r)\n",
    "    x2r = lstm2(x2r)\n",
    "\n",
    "    ## DENSE\n",
    "    x = Concatenate(axis=1)([x1r, x2r])\n",
    "    x = Dense(200)(x)\n",
    "    x = Dense(1)(x)\n",
    "    out = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=[input1, input2], outputs=out)\n",
    "    model.compile(optimizer=config['OPTIMIZER'], loss='binary_crossentropy', metrics=[\"acc\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a custom loss function\n",
    "\n",
    "here we will use the f1 score just for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evalF1(model, x_val, y_val, **kwargs):\n",
    "    preds = model.predict(x_val)\n",
    "    preds = np.round(preds)\n",
    "    return f1_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instantiate a KerasGridSearchCV object and call fit to grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_extras.model_selection import KerasGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycv = KerasGridSearchCV(getModel, configs, eval_model=evalF1, epochs=1, k=3, verbose=False, k_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "testing 1 :\n",
      "embed_size :\t 100\n",
      "cell_size :\t 100\n",
      "drop_rate :\t 0.25\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.7054263565891472\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.7104247104247104\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6504065040650406\n",
      "\n",
      "final avg score : 0.688752523692966\n",
      "\n",
      "new best model with avg score 0.688752523692966\n",
      "\n",
      "\n",
      "testing 2 :\n",
      "embed_size :\t 100\n",
      "cell_size :\t 100\n",
      "drop_rate :\t 0.5\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.7054263565891472\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.7104247104247104\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6504065040650406\n",
      "\n",
      "final avg score : 0.688752523692966\n",
      "\n",
      "\n",
      "testing 3 :\n",
      "embed_size :\t 100\n",
      "cell_size :\t 200\n",
      "drop_rate :\t 0.25\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/envs/oldkeras/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation score : 0.0\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.7104247104247104\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6504065040650406\n",
      "\n",
      "final avg score : 0.453610404829917\n",
      "\n",
      "\n",
      "testing 4 :\n",
      "embed_size :\t 100\n",
      "cell_size :\t 200\n",
      "drop_rate :\t 0.5\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.6901960784313725\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.0\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6504065040650406\n",
      "\n",
      "final avg score : 0.4468675274988044\n",
      "\n",
      "\n",
      "testing 5 :\n",
      "embed_size :\t 200\n",
      "cell_size :\t 100\n",
      "drop_rate :\t 0.25\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.6296296296296297\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.7407407407407408\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6504065040650406\n",
      "\n",
      "final avg score : 0.6735922914784703\n",
      "\n",
      "\n",
      "testing 6 :\n",
      "embed_size :\t 200\n",
      "cell_size :\t 100\n",
      "drop_rate :\t 0.5\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.7054263565891472\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.7104247104247104\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6504065040650406\n",
      "\n",
      "final avg score : 0.688752523692966\n",
      "\n",
      "\n",
      "testing 7 :\n",
      "embed_size :\t 200\n",
      "cell_size :\t 200\n",
      "drop_rate :\t 0.25\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.5319148936170213\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.7272727272727273\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6584362139917695\n",
      "\n",
      "final avg score : 0.639207944960506\n",
      "\n",
      "\n",
      "testing 8 :\n",
      "embed_size :\t 200\n",
      "cell_size :\t 200\n",
      "drop_rate :\t 0.5\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.7054263565891472\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.7104247104247104\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6504065040650406\n",
      "\n",
      "final avg score : 0.688752523692966\n",
      "\n",
      "best params:\n",
      "{'embed_size': 100, 'cell_size': 100, 'drop_rate': 0.25, 'OPTIMIZER': 'adam', 'MAXLEN': 64, 'VOCAB': 38}\n"
     ]
    }
   ],
   "source": [
    "best, trials, scores = mycv.fit([x1, x2], y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAXLEN': 64,\n",
       " 'OPTIMIZER': 'adam',\n",
       " 'VOCAB': 38,\n",
       " 'cell_size': 100,\n",
       " 'drop_rate': 0.25,\n",
       " 'embed_size': 100}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldkeras",
   "language": "python",
   "name": "oldkeras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
