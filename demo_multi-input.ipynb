{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-validation script for keras models\n",
    "\n",
    "this model demonstrates a multi-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/envs/oldkeras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/derek/miniconda3/envs/oldkeras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict GPU usage here - just for testing\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data construction\n",
    "\n",
    "we will compare texts in the Brown corpus from different genres provided by NLTK.\n",
    "\n",
    "the model will accept two lines of text, and try to classify as `same-source==1` or `different-source==0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "government = [s for s in brown.sents(categories=['government']) if len(s) > 30]\n",
    "religion = [s for s in brown.sents(categories=['religion']) if len(s) > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some samples\n",
    "def generateData(a, b, samples=1000):\n",
    "    x1, x2, y = [], [], []\n",
    "    for i in range(samples):\n",
    "        # decide whether to use same of different\n",
    "        g = np.random.randint(2)\n",
    "        h = np.random.randint(2)\n",
    "        if g > 0:\n",
    "            a_s = a[:]\n",
    "        else:\n",
    "            a_s = b[:]\n",
    "        if h > 0:\n",
    "            b_s = a[:]\n",
    "        else:\n",
    "            b_s = b[:]\n",
    "        x1.append(a_s[np.random.randint(len(a_s))])\n",
    "        x2.append(b_s[np.random.randint(len(b_s))])\n",
    "        if g == h:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    return x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, y = generateData(government, religion, samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# character-tokenize\n",
    "import re\n",
    "def charTokenize(txt):\n",
    "    seqs = []\n",
    "    for l in txt:\n",
    "        ll = ' '.join(l).lower()\n",
    "        ll = re.sub(r'[^0-9a-z\\s]', '', ll)\n",
    "        seqs.append(list(ll))\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = charTokenize(x1)\n",
    "x2 = charTokenize(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index and pad the data\n",
    "class CharIndexer:\n",
    "    def __init__(self, max_len=64, chars='abcdefghijklmnopqrstuvwxyz0123456789 '):\n",
    "        self.char2idx=dict([(c, i+1) for i, c in enumerate(list(chars))]+[('O', 0)])\n",
    "        self.idx2char=dict([(i+1, c) for i, c in enumerate(list(chars))]+[(0, 'O')])\n",
    "        self.max_len=max_len\n",
    "    \n",
    "    def transform(self, lol):\n",
    "        seqs = []\n",
    "        for l in lol:\n",
    "            s = [self.char2idx[c] for c in l]\n",
    "            s = s + [0 for _ in range(self.max_len)]\n",
    "            s = s[:self.max_len]\n",
    "            seqs.append(s)\n",
    "        return np.array(seqs)\n",
    "    \n",
    "    def inverse_transform(self, lol, no_pad=True):\n",
    "        txt = []\n",
    "        for l in lol:\n",
    "            l = [self.idx2char[i] for i in l]\n",
    "            if no_pad:\n",
    "                l = [c for c in l if c != 'O']\n",
    "            txt.append(l)\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxr = CharIndexer()\n",
    "x1 = idxr.transform(x1)\n",
    "x2 = idxr.transform(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : as another thanksgiving draws near  let us take time out from th \t in the event that agreement is not reached on the use of the rup\n",
      "1 : in fact  during the first century bc  an extensive literature sp \t thus  america   the most widely sung of the patriotic songs  was\n",
      "0 : the action of the commission in allowing or denying any claim un \t how explicit such factors have been historically is evident in a\n",
      "0 :  2  realtors realize  of course  that they are involved in an in \t mr devey will be responsible for the commercial expansion of vec\n",
      "0 : it is not unfair to add on the other side that the crude and alm \t and so  let us remember on this day not only to thank the almigh\n",
      "0 : conduct engineering research and technical development work to d \t after all this destruction of old literature  it should be obvio\n",
      "1 : we should not allow the image of an immanent end brought about i \t all this emphasis on centrality and on the number 5 as a symboli\n",
      "1 : rather  such assignments are made  as they must be  on the basis \t as the result of an exhaustive review of the recommendations con\n",
      "1 : he will be considered not only great among his contemporaries  b \t although a similar situs for tangible property is mentioned in t\n",
      "1 : so it is too with many other spirits which we all know  the spir \t for this does not account for the integral  elemental power of t\n"
     ]
    }
   ],
   "source": [
    "# check data and transformers\n",
    "for i in range(10):\n",
    "    print(y[i], \":\", ''.join(idxr.inverse_transform([x1[i]])[0]), '\\t', ''.join(idxr.inverse_transform([x2[i]])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of y's and reshape\n",
    "print(len([x for x in y if x==0]), len([x for x in y if x==1]))\n",
    "y = np.array(y)[:, np.newaxis]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define hyperparameters to search over\n",
    "\n",
    "if we define constants with UPPERCASE, they won't be shown in the `verbose` printout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'embed_size' : [100, 200],\n",
    "    'cell_size': [100, 200],\n",
    "    'drop_rate': [0.25, 0.5],\n",
    "    'OPTIMIZER' : ['adam'],\n",
    "    'MAXLEN': [64],\n",
    "    'VOCAB' : [len(idxr.char2idx)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model testing\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Bidirectional, Embedding, Dropout, LSTM, Concatenate, Dense, Activation\n",
    "\n",
    "def getModel(config):\n",
    "\n",
    "    input1 = Input((config['MAXLEN'],))\n",
    "    input2 = Input((config['MAXLEN'],))\n",
    "\n",
    "    embedd = Embedding(config['VOCAB'], config['embed_size'], input_length=config['MAXLEN'])\n",
    "\n",
    "    ## RNN\n",
    "    lstm1 = Bidirectional(LSTM(config['cell_size'], return_sequences=True))\n",
    "    lstm2 = Bidirectional(LSTM(config['cell_size']))\n",
    "\n",
    "    x1r = embedd(input1)\n",
    "    x1r = Dropout(config['drop_rate'])(x1r)\n",
    "    x1r = lstm1(x1r)\n",
    "    x1r = Dropout(config['drop_rate'])(x1r)\n",
    "    x1r = lstm2(x1r)\n",
    "\n",
    "    x2r = embedd(input2)\n",
    "    x2r = Dropout(config['drop_rate'])(x2r)\n",
    "    x2r = lstm1(x2r)\n",
    "    x2r = Dropout(config['drop_rate'])(x2r)\n",
    "    x2r = lstm2(x2r)\n",
    "\n",
    "    ## DENSE\n",
    "    x = Concatenate(axis=1)([x1r, x2r])\n",
    "    x = Dense(200)(x)\n",
    "    x = Dense(1)(x)\n",
    "    out = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=[input1, input2], outputs=out)\n",
    "    model.compile(optimizer=config['OPTIMIZER'], loss='binary_crossentropy', metrics=[\"acc\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a custom loss function\n",
    "\n",
    "here we will use the f1 score just for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evalF1(model, x_val, y_val, **kwargs):\n",
    "    preds = model.predict(x_val)\n",
    "    preds = np.round(preds)\n",
    "    return f1_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instantiate a KerasGridSearchCV object and call fit to grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_extras.model_selection import KerasGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycv = KerasGridSearchCV(getModel, configs, eval_model=evalF1, epochs=1, k=3, verbose=False, k_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "testing 1 :\n",
      "embed_size :\t 100\n",
      "cell_size :\t 100\n",
      "drop_rate :\t 0.25\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/envs/oldkeras/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation score : 0.0\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.5680473372781065\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.0\n",
      "\n",
      "final avg score : 0.1893491124260355\n",
      "\n",
      "new best model with avg score 0.1893491124260355\n",
      "\n",
      "\n",
      "testing 2 :\n",
      "embed_size :\t 100\n",
      "cell_size :\t 100\n",
      "drop_rate :\t 0.5\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.0\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.34615384615384615\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.5263157894736842\n",
      "\n",
      "final avg score : 0.2908232118758434\n",
      "\n",
      "new best model with avg score 0.2908232118758434\n",
      "\n",
      "\n",
      "testing 3 :\n",
      "embed_size :\t 100\n",
      "cell_size :\t 200\n",
      "drop_rate :\t 0.25\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.08163265306122451\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.4675324675324675\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6557377049180327\n",
      "\n",
      "final avg score : 0.401634275170575\n",
      "\n",
      "new best model with avg score 0.401634275170575\n",
      "\n",
      "\n",
      "testing 4 :\n",
      "embed_size :\t 100\n",
      "cell_size :\t 200\n",
      "drop_rate :\t 0.5\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.0\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.13636363636363635\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6638655462184875\n",
      "\n",
      "final avg score : 0.2667430608607079\n",
      "\n",
      "\n",
      "testing 5 :\n",
      "embed_size :\t 200\n",
      "cell_size :\t 100\n",
      "drop_rate :\t 0.25\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.0425531914893617\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.6367346938775511\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.4666666666666667\n",
      "\n",
      "final avg score : 0.3819848506778598\n",
      "\n",
      "\n",
      "testing 6 :\n",
      "embed_size :\t 200\n",
      "cell_size :\t 100\n",
      "drop_rate :\t 0.5\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.47058823529411764\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.6367346938775511\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6502057613168724\n",
      "\n",
      "final avg score : 0.5858428968295137\n",
      "\n",
      "new best model with avg score 0.5858428968295137\n",
      "\n",
      "\n",
      "testing 7 :\n",
      "embed_size :\t 200\n",
      "cell_size :\t 200\n",
      "drop_rate :\t 0.25\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.7054263565891472\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.6367346938775511\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.652542372881356\n",
      "\n",
      "final avg score : 0.6649011411160181\n",
      "\n",
      "new best model with avg score 0.6649011411160181\n",
      "\n",
      "\n",
      "testing 8 :\n",
      "embed_size :\t 200\n",
      "cell_size :\t 200\n",
      "drop_rate :\t 0.5\n",
      "\n",
      "\n",
      "training 1 th fold...\n",
      "evaluating 1 th fold...\n",
      "evaluation score : 0.658008658008658\n",
      "\n",
      "training 2 th fold...\n",
      "evaluating 2 th fold...\n",
      "evaluation score : 0.6367346938775511\n",
      "\n",
      "training 3 th fold...\n",
      "evaluating 3 th fold...\n",
      "evaluation score : 0.6439024390243901\n",
      "\n",
      "final avg score : 0.6462152636368664\n",
      "\n",
      "best params:\n",
      "{'embed_size': 200, 'cell_size': 200, 'drop_rate': 0.25, 'OPTIMIZER': 'adam', 'MAXLEN': 64, 'VOCAB': 38}\n"
     ]
    }
   ],
   "source": [
    "best, trials, scores = mycv.fit([x1, x2], y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAXLEN': 64,\n",
       " 'OPTIMIZER': 'adam',\n",
       " 'VOCAB': 38,\n",
       " 'cell_size': 200,\n",
       " 'drop_rate': 0.25,\n",
       " 'embed_size': 200}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldkeras",
   "language": "python",
   "name": "oldkeras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
